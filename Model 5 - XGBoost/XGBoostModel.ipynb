{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all imports related to data engineering\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training json file, then close the file\n",
    "file = open(\"train.json\")\n",
    "raw_data = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_number_encoding = {\n",
    "    'B-NAME_STUDENT': 0, \n",
    "    'I-NAME_STUDENT': 1, \n",
    "    'B-URL_PERSONAL': 2, \n",
    "    'B-EMAIL': 3, \n",
    "    'B-ID_NUM': 4, \n",
    "    'I-URL_PERSONAL': 5, \n",
    "    'B-USERNAME': 6, \n",
    "    'I-PHONE_NUM': 7,  \n",
    "    'B-STREET_ADDRESS': 8, \n",
    "    'I-STREET_ADDRESS': 9,  \n",
    "    'B-PHONE_NUM': 10, \n",
    "    'I-ID_NUM': 11,\n",
    "    'O': 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'to', 'and', 'a', 'in', 'is', 'it', 'you', 'that', 'he', 'was', 'for', 'on', 'are', 'with', 'as', 'I', 'his', 'they', 'be', 'at', 'one', 'have', 'this', 'from', 'or', 'had', 'by', 'not', 'word', 'but', 'what', 'some', 'we', 'can', 'out', 'other', 'were', 'all', 'there', 'when', 'up', 'use', 'your', 'how', 'said', 'an', 'each', 'she', 'which', 'do', 'their', 'time', 'if', 'will', 'way', 'about', 'many', 'then', 'them', 'write', 'would', 'like', 'so', 'these', 'her', 'long', 'make', 'thing', 'see', 'him', 'two', 'has', 'look', 'more', 'day', 'could', 'go', 'come', 'did', 'number', 'sound', 'no', 'most', 'people', 'my', 'over', 'know', 'water', 'than', 'call', 'first', 'who', 'may', 'down', 'side', 'been', 'now', 'find', 'any', 'new', 'work', 'part', 'take', 'get', 'place', 'made', 'live', 'where', 'after', 'back', 'little', 'only', 'round', 'man', 'year', 'came', 'show', 'every', 'good', 'me', 'give', 'our', 'under', 'name', 'very', 'through', 'just', 'form', 'sentence', 'great', 'think', 'say', 'help', 'low', 'line', 'differ', 'turn', 'cause', 'much', 'mean', 'before', 'move', 'right', 'boy', 'old', 'too', 'same', 'tell', 'does', 'set', 'three', 'want', 'air', 'well', 'also', 'play', 'small', 'end', 'put', 'home', 'read', 'hand', 'port', 'large', 'spell', 'add', 'even', 'land', 'here', 'must', 'big', 'high', 'such', 'follow', 'act', 'why', 'ask', 'men', 'change', 'went', 'light', 'kind', 'off', 'need', 'house', 'picture', 'try', 'us', 'again', 'animal', 'point', 'mother', 'world', 'near', 'build', 'self', 'earth', 'father', 'head', 'stand', 'own', 'page', 'should', 'country', 'found', 'answer', 'school', 'grow', 'study', 'still', 'learn', 'plant', 'cover', 'food', 'sun', 'four', 'between', 'state', 'keep', 'eye', 'never', 'last', 'let', 'thought', 'city', 'tree', 'cross', 'farm', 'hard', 'start', 'might', 'story', 'saw', 'far', 'sea', 'draw', 'left', 'late', 'run', \"don't\", 'while', 'press', 'close', 'night', 'real', 'life', 'few', 'north', 'open', 'seem', 'together', 'next', 'white', 'children', 'begin', 'got', 'walk', 'example', 'ease', 'paper', 'group', 'always', 'music', 'those', 'both', 'mark', 'often', 'letter', 'until', 'mile', 'river', 'car', 'feet', 'care', 'second', 'book', 'carry', 'took', 'science', 'eat', 'room', 'friend', 'began', 'idea', 'fish', 'mountain', 'stop', 'once', 'base', 'hear', 'horse', 'cut', 'sure', 'watch', 'color', 'face', 'wood', 'main', 'enough', 'plain', 'girl', 'usual', 'young', 'ready', 'above', 'ever', 'red', 'list', 'though', 'feel', 'talk', 'bird', 'soon', 'body', 'dog', 'family', 'direct', 'pose', 'leave', 'song', 'measure', 'door', 'product', 'black', 'short', 'numeral', 'class', 'wind', 'question', 'happen', 'complete', 'ship', 'area', 'half', 'rock', 'order', 'fire', 'south', 'problem', 'piece', 'told', 'knew', 'pass', 'since', 'top', 'whole', 'king', 'space', 'heard', 'best', 'hour', 'better', 'true', 'during', 'hundred', 'five', 'remember', 'step', 'early', 'hold', 'west', 'ground', 'interest', 'reach', 'fast', 'verb', 'sing', 'listen', 'six', 'table', 'travel', 'less', 'morning', 'ten', 'simple', 'several', 'vowel', 'toward', 'war', 'lay', 'against', 'pattern', 'slow', 'center', 'love', 'person', 'money', 'serve', 'appear', 'road', 'map', 'rain', 'rule', 'govern', 'pull', 'cold', 'notice', 'voice', 'unit', 'power', 'town', 'fine', 'certain', 'fly', 'fall', 'lead', 'cry', 'dark', 'machine', 'note', 'wait', 'plan', 'figure', 'star', 'box', 'noun', 'field', 'rest', 'correct', 'able', 'pound', 'done', 'beauty', 'drive', 'stood', 'contain', 'front', 'teach', 'week', 'final', 'gave', 'green', 'oh', 'quick', 'develop', 'ocean', 'warm', 'free', 'minute', 'strong', 'special', 'mind', 'behind', 'clear', 'tail', 'produce', 'fact', 'street', 'inch', 'multiply', 'nothing', 'course', 'stay', 'wheel', 'full', 'force', 'blue', 'object', 'decide', 'surface', 'deep', 'moon', 'island', 'foot', 'system', 'busy', 'test', 'record', 'boat', 'common', 'gold', 'possible', 'plane', 'stead', 'dry', 'wonder', 'laugh', 'thousand', 'ago', 'ran', 'check', 'game', 'shape', 'equate', 'hot', 'miss', 'brought', 'heat', 'snow', 'tire', 'bring', 'yes', 'distant', 'fill', 'east', 'paint', 'language', 'among', 'grand', 'ball', 'yet', 'wave', 'drop', 'heart', 'am', 'present', 'heavy', 'dance', 'engine', 'position', 'arm', 'wide', 'sail', 'material', 'size', 'vary', 'settle', 'speak', 'weight', 'general', 'ice', 'matter', 'circle', 'pair', 'include', 'divide', 'syllable', 'felt', 'perhaps', 'pick', 'sudden', 'count', 'square', 'reason', 'length', 'represent', 'art', 'subject', 'region', 'energy', 'hunt', 'probable', 'bed', 'brother', 'egg', 'ride', 'cell', 'believe', 'fraction', 'forest', 'sit', 'race', 'window', 'store', 'summer', 'train', 'sleep', 'prove', 'lone', 'leg', 'exercise', 'wall', 'catch', 'mount', 'wish', 'sky', 'board', 'joy', 'winter', 'sat', 'written', 'wild', 'instrument', 'kept', 'glass', 'grass', 'cow', 'job', 'edge', 'sign', 'visit', 'past', 'soft', 'fun', 'bright', 'gas', 'weather', 'month', 'million', 'bear', 'finish', 'happy', 'hope', 'flower', 'clothe', 'strange', 'gone', 'jump', 'baby', 'eight', 'village', 'meet', 'root', 'buy', 'raise', 'solve', 'metal', 'whether', 'push', 'seven', 'paragraph', 'third', 'shall', 'held', 'hair', 'describe', 'cook', 'floor', 'either', 'result', 'burn', 'hill', 'safe', 'cat', 'century', 'consider', 'type', 'law', 'bit', 'coast', 'copy', 'phrase', 'silent', 'tall', 'sand', 'soil', 'roll', 'temperature', 'finger', 'industry', 'value', 'fight', 'lie', 'beat', 'excite', 'natural', 'view', 'sense', 'ear', 'else', 'quite', 'broke', 'case', 'middle', 'kill', 'son', 'lake', 'moment', 'scale', 'loud', 'spring', 'observe', 'child', 'straight', 'consonant', 'nation', 'dictionary', 'milk', 'speed', 'method', 'organ', 'pay', 'age', 'section', 'dress', 'cloud', 'surprise', 'quiet', 'stone', 'tiny', 'climb', 'cool', 'design', 'poor', 'lot', 'experiment', 'bottom', 'key', 'iron', 'single', 'stick', 'flat', 'twenty', 'skin', 'smile', 'crease', 'hole', 'trade', 'melody', 'trip', 'office', 'receive', 'row', 'mouth', 'exact', 'symbol', 'die', 'least', 'trouble', 'shout', 'except', 'wrote', 'seed', 'tone', 'join', 'suggest', 'clean', 'break', 'lady', 'yard', 'rise', 'bad', 'blow', 'oil', 'blood', 'touch', 'grew', 'cent', 'mix', 'team', 'wire', 'cost', 'lost', 'brown', 'wear', 'garden', 'equal', 'sent', 'choose', 'fell', 'fit', 'flow', 'fair', 'bank', 'collect', 'save', 'control', 'decimal', 'gentle', 'woman', 'captain', 'practice', 'separate', 'difficult', 'doctor', 'please', 'protect', 'noon', 'whose', 'locate', 'ring', 'character', 'insect', 'caught', 'period', 'indicate', 'radio', 'spoke', 'atom', 'human', 'history', 'effect', 'electric', 'expect', 'crop', 'modern', 'element', 'hit', 'student', 'corner', 'party', 'supply', 'bone', 'rail', 'imagine', 'provide', 'agree', 'thus', 'capital', \"won't\", 'chair', 'danger', 'fruit', 'rich', 'thick', 'soldier', 'process', 'operate', 'guess', 'necessary', 'sharp', 'wing', 'create', 'neighbor', 'wash', 'bat', 'rather', 'crowd', 'corn', 'compare', 'poem', 'string', 'bell', 'depend', 'meat', 'rub', 'tube', 'famous', 'dollar', 'stream', 'fear', 'sight', 'thin', 'triangle', 'planet', 'hurry', 'chief', 'colony', 'clock', 'mine', 'tie', 'enter', 'major', 'fresh', 'search', 'send', 'yellow', 'gun', 'allow', 'print', 'dead', 'spot', 'desert', 'suit', 'current', 'lift', 'rose', 'continue', 'block', 'chart', 'hat', 'sell', 'success', 'company', 'subtract', 'event', 'particular', 'deal', 'swim', 'term', 'opposite', 'wife', 'shoe', 'shoulder', 'spread', 'arrange', 'camp', 'invent', 'cotton', 'born', 'determine', 'quart', 'nine', 'truck', 'noise', 'level', 'chance', 'gather', 'shop', 'stretch', 'throw', 'shine', 'property', 'column', 'molecule', 'select', 'wrong', 'gray', 'repeat', 'require', 'broad', 'prepare', 'salt', 'nose', 'plural', 'anger', 'claim', 'continent', 'oxygen', 'sugar', 'death', 'pretty', 'skill', 'women', 'season', 'solution', 'magnet', 'silver', 'thank', 'branch', 'match', 'suffix', 'especially', 'fig', 'afraid', 'huge', 'sister', 'steel', 'discuss', 'forward', 'similar', 'guide', 'experience', 'score', 'apple', 'bought', 'led', 'pitch', 'coat', 'mass', 'card', 'band', 'rope', 'slip', 'win', 'dream', 'evening', 'condition', 'feed', 'tool', 'total', 'basic', 'smell', 'valley', 'nor', 'double', 'seat', 'arrive', 'master', 'track', 'parent', 'shore', 'division', 'sheet', 'substance', 'favor', 'connect', 'post', 'spend', 'chord', 'fat', 'glad', 'original', 'share', 'station', 'dad', 'bread', 'charge', 'proper', 'bar', 'offer', 'segment', 'slave', 'duck', 'instant', 'market', 'degree', 'populate', 'chick', 'dear', 'enemy', 'reply', 'drink', 'occur', 'support', 'speech', 'nature', 'range', 'steam', 'motion', 'path', 'liquid', 'log', 'meant', 'quotient', 'teeth', 'shell', 'nec', '\\n\\n', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "# Got the txt file from here: https://gist.github.com/deekayen/4148741\n",
    "\n",
    "# Common words List to hold common words\n",
    "with open(\"most-common-words.txt\", \"r\") as common_words_file:\n",
    "    common_tokens = [word[:-1] for word in list(common_words_file)]\n",
    "    common_tokens.append(\"\\n\\n\")\n",
    "    common_tokens.append(\"\\n\")\n",
    "    common_tokens.append(\" \")\n",
    "\n",
    "# Add punctuation to the list of commonalities\n",
    "for char in list(string.punctuation):\n",
    "    common_tokens.append(char)\n",
    "\n",
    "print(common_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get rid of the 1000 most common used words\n",
    "def common_word_drop(token_list, whitespace_list, label_list, rows):\n",
    "    for word in common_tokens:\n",
    "        if word in token_list:\n",
    "            indices = [i for i, x in enumerate(token_list) if x.lower() == word]\n",
    "            token_list = [token_list[i] for i in range(len(token_list)) if i not in indices]\n",
    "            whitespace_list = [whitespace_list[i] for i in range(len(whitespace_list)) if i not in indices]\n",
    "            label_list = [label_list[i] for i in range(len(label_list)) if i not in indices]\n",
    "            rows = [rows[i] for i in range(len(rows)) if i not in indices]\n",
    "\n",
    "    return token_list, whitespace_list, label_list, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows(full_tokens):\n",
    "    rows = []\n",
    "    row_num = 1\n",
    "    for token in full_tokens:\n",
    "        rows.append(row_num)\n",
    "        if token == \"\\n\\n\" or token == \"\\n\":\n",
    "            row_num = row_num + 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pii_data_exists(labels):\n",
    "    # Loop over and see if a PII data is found, if it is, return True, else False.\n",
    "    for label in labels:\n",
    "        if label != 'O':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_label(labels):\n",
    "\n",
    "    # Initialize the indexer and for all labels, find the indexes that have PII data\n",
    "    label_indexes = []\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] != 'O':\n",
    "            label_indexes.append(i)\n",
    "    \n",
    "    # If there is no PII data, if only one PII data, else multiple data\n",
    "    if len(label_indexes) == 0:\n",
    "        return [-1 for label in labels]\n",
    "    elif len(label_indexes) == 1:\n",
    "        label_range = [-1 for label in labels]\n",
    "        label_range[label_indexes[0]] = 0\n",
    "        return label_range\n",
    "    else:\n",
    "        label_range = [-1 for label in labels]\n",
    "\n",
    "        # Get distance for first PII\n",
    "        first_index = label_indexes[0]\n",
    "        first_pii_distance = label_indexes[1] - label_indexes[0]\n",
    "        label_range[first_index] = first_pii_distance\n",
    "\n",
    "        # Get distance for last PII\n",
    "        last_index = label_indexes[-1]\n",
    "        last_pii_distance = label_indexes[-1] - label_indexes[-2]\n",
    "        label_range[last_index] = last_pii_distance\n",
    "        \n",
    "        # Loop over the second to second last PII and get the distances.\n",
    "        for idx in range(1, len(label_indexes)-1):\n",
    "\n",
    "            # For the middle PII data points. Set the previous and next PII\n",
    "            current_pii = label_indexes[idx]\n",
    "            previous_pii = label_indexes[idx-1]\n",
    "            next_pii = label_indexes[idx+1]\n",
    "\n",
    "            # distances\n",
    "            prev_dist = current_pii - previous_pii\n",
    "            next_dist = next_pii - current_pii\n",
    "\n",
    "            # Append the shortest distance to the current pii data\n",
    "            label_range[current_pii] = min(prev_dist, next_dist)\n",
    "        \n",
    "        # Return the label range.\n",
    "        return label_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_data_for_model(data):\n",
    "\n",
    "    # Get the first value from the data\n",
    "    first_doc = data[0]\n",
    "\n",
    "    # Get rid of common words\n",
    "    all_rows = get_rows(first_doc['tokens'])\n",
    "    tokens, white_spaces, labels, rows = common_word_drop(first_doc['tokens'], first_doc['trailing_whitespace'], first_doc['labels'], all_rows)\n",
    "    closest_labels = get_closest_label(labels)\n",
    "\n",
    "    # Create the initial dataframe from the above data\n",
    "    first_doc_data = {\n",
    "        \"tokens\": tokens,\n",
    "        \"trailing_whitespaces\": white_spaces,\n",
    "        \"capitalized first char\": [True if label[0].isupper() else False for label in tokens],\n",
    "        \"token length\": [len(token) for token in tokens],\n",
    "        \"is_numeric\": [True if token.isnumeric() else False for token in tokens],\n",
    "        \"PII label\": labels,\n",
    "        \"Row\": rows,\n",
    "        \"Closest PII data\": closest_labels\n",
    "    }\n",
    "    raw_df = pd.DataFrame(first_doc_data)\n",
    "\n",
    "    # Loop till the end of the data\n",
    "    for document in data[1: len(data) - 1]:\n",
    "\n",
    "        # Check to see if there exists PII data\n",
    "        if not pii_data_exists(document['labels']):\n",
    "            continue\n",
    "            \n",
    "        # Get rid of common words\n",
    "        all_rows = get_rows(document['tokens'])\n",
    "        tokens, white_spaces, labels, rows = common_word_drop(document['tokens'], document['trailing_whitespace'], document['labels'], all_rows)\n",
    "        closest_labels = get_closest_label(labels)\n",
    "\n",
    "        # Collect the data in the same way\n",
    "        doc_data = {\n",
    "            \"tokens\": tokens,\n",
    "            \"trailing_whitespaces\": white_spaces,\n",
    "            \"capitalized first char\": [True if label[0].isupper() else False for label in tokens],\n",
    "            \"token length\": [len(token) for token in tokens],\n",
    "            \"is_numeric\": [True if token.isnumeric() else False for token in tokens],\n",
    "            \"PII label\": labels,\n",
    "            \"Row\": rows,\n",
    "            \"Closest PII data\": closest_labels\n",
    "        }\n",
    "        df = pd.DataFrame(doc_data)\n",
    "\n",
    "        # Concatenate all the data into one single dataframe\n",
    "        raw_df = pd.concat([raw_df, df], ignore_index=True, sort=False)\n",
    "\n",
    "    # Return the concatenated dataframe\n",
    "    return raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespaces</th>\n",
       "      <th>capitalized first char</th>\n",
       "      <th>token length</th>\n",
       "      <th>is_numeric</th>\n",
       "      <th>PII label</th>\n",
       "      <th>Row</th>\n",
       "      <th>Closest PII data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thinking</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>innovation</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reflexion</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avril</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276038</th>\n",
       "      <td>However</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276039</th>\n",
       "      <td>hindrance</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276040</th>\n",
       "      <td>stimulate</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276041</th>\n",
       "      <td>innovative</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276042</th>\n",
       "      <td>thinking</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276043 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tokens  trailing_whitespaces  capitalized first char  \\\n",
       "0         Thinking                  True                    True   \n",
       "1       innovation                  True                   False   \n",
       "2        reflexion                 False                   False   \n",
       "3            Avril                  True                    True   \n",
       "4             2021                 False                   False   \n",
       "...            ...                   ...                     ...   \n",
       "276038     However                 False                    True   \n",
       "276039   hindrance                  True                   False   \n",
       "276040   stimulate                  True                   False   \n",
       "276041  innovative                 False                   False   \n",
       "276042    thinking                  True                   False   \n",
       "\n",
       "        token length  is_numeric PII label  Row  Closest PII data  \n",
       "0                  8       False         O    1                -1  \n",
       "1                 10       False         O    1                -1  \n",
       "2                  9       False         O    1                -1  \n",
       "3                  5       False         O    1                -1  \n",
       "4                  4        True         O    1                -1  \n",
       "...              ...         ...       ...  ...               ...  \n",
       "276038             7       False         O   32                -1  \n",
       "276039             9       False         O   32                -1  \n",
       "276040             9       False         O   32                -1  \n",
       "276041            10       False         O   32                -1  \n",
       "276042             8       False         O   33                -1  \n",
       "\n",
       "[276043 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the training data and get rid of some unneeded number values\n",
    "# data = engineer_data_for_model(raw_data[0:100])\n",
    "data = engineer_data_for_model(raw_data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# hashing_vectorizer = HashingVectorizer(n_features=8, norm=None, alternate_sign=False)\n",
    "\n",
    "# encoded_tokens = hashing_vectorizer.transform(data[\"tokens\"]).toarray()\n",
    "\n",
    "# encoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hashlib\n",
    "\n",
    "# hashed_values = [hashlib.sha1(row.tobytes()).hexdigest() for row in encoded_tokens]\n",
    "\n",
    "# hashed_integers = [int(hash_val, 16) for hash_val in hashed_values]\n",
    "# hashed_integers[0]\n",
    "\n",
    "# data[\"hashed_tokens\"] = hashed_integers\n",
    "# data.astype({'hashed_tokens': 'int64'}).dtypes\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespaces</th>\n",
       "      <th>capitalized first char</th>\n",
       "      <th>token length</th>\n",
       "      <th>is_numeric</th>\n",
       "      <th>PII label</th>\n",
       "      <th>Row</th>\n",
       "      <th>Closest PII data</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thinking</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>innovation</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reflexion</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avril</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276038</th>\n",
       "      <td>However</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276039</th>\n",
       "      <td>hindrance</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276040</th>\n",
       "      <td>stimulate</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276041</th>\n",
       "      <td>innovative</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276042</th>\n",
       "      <td>thinking</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276043 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tokens  trailing_whitespaces  capitalized first char  \\\n",
       "0         Thinking                  True                    True   \n",
       "1       innovation                  True                   False   \n",
       "2        reflexion                 False                   False   \n",
       "3            Avril                  True                    True   \n",
       "4             2021                 False                   False   \n",
       "...            ...                   ...                     ...   \n",
       "276038     However                 False                    True   \n",
       "276039   hindrance                  True                   False   \n",
       "276040   stimulate                  True                   False   \n",
       "276041  innovative                 False                   False   \n",
       "276042    thinking                  True                   False   \n",
       "\n",
       "        token length  is_numeric PII label  Row  Closest PII data   Y  \n",
       "0                  8       False         O    1                -1  12  \n",
       "1                 10       False         O    1                -1  12  \n",
       "2                  9       False         O    1                -1  12  \n",
       "3                  5       False         O    1                -1  12  \n",
       "4                  4        True         O    1                -1  12  \n",
       "...              ...         ...       ...  ...               ...  ..  \n",
       "276038             7       False         O   32                -1  12  \n",
       "276039             9       False         O   32                -1  12  \n",
       "276040             9       False         O   32                -1  12  \n",
       "276041            10       False         O   32                -1  12  \n",
       "276042             8       False         O   33                -1  12  \n",
       "\n",
       "[276043 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Multinomial encoding \n",
    "le = LabelEncoder()\n",
    "data['Y'] = le.fit_transform(data['PII label'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 2, 8, 5, 0, 1, 11, 6, 9, 4, 10, 3, 7]\n",
      "Actual values of encoded labels:\n",
      "['O' 'B-NAME_STUDENT' 'I-NAME_STUDENT' 'B-URL_PERSONAL' 'B-EMAIL'\n",
      " 'B-ID_NUM' 'I-URL_PERSONAL' 'B-USERNAME' 'I-PHONE_NUM' 'B-STREET_ADDRESS'\n",
      " 'I-STREET_ADDRESS' 'B-PHONE_NUM' 'I-ID_NUM']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique values and print them.\n",
    "unique_list = data[\"Y\"].unique().tolist()\n",
    "print(unique_list)\n",
    "\n",
    "# Display the actual values of the encoded labels\n",
    "inverse_encoded_classes = le.inverse_transform(unique_list)\n",
    "print(\"Actual values of encoded labels:\")\n",
    "print(inverse_encoded_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/Train Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train_x = 193230 \n",
      " Length y_train = 193230\n",
      "Length test_x = 82813 \n",
      " Length test_y = 82813\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "y_train = train_data[\"Y\"].to_numpy()\n",
    "X_train = train_data.drop(columns=[\"tokens\", \"PII label\"])\n",
    "print(f\"Length train_x = {len(X_train)} \\n Length y_train = {len(y_train)}\")\n",
    "\n",
    "\n",
    "# Test data\n",
    "y_test = test_data[\"Y\"].to_numpy()\n",
    "X_test = test_data.drop(columns=[\"tokens\", \"PII label\"])\n",
    "print(f\"Length test_x = {len(X_test)} \\n Length test_y = {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11], got [ 0  1  2  3  4  5  6  7  8  9 10 12]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create and train the XGBoost Classifier\u001b[39;00m\n\u001b[0;32m      7\u001b[0m clf \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\xgboost\\sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1468\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1470\u001b[0m ):\n\u001b[1;32m-> 1471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1472\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1474\u001b[0m     )\n\u001b[0;32m   1476\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11], got [ 0  1  2  3  4  5  6  7  8  9 10 12]"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create and train the XGBoost Classifier\n",
    "clf = XGBClassifier(n_estimators=100, random_state=42, enable_categorical=True)\n",
    "clf.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print('Training accuracy:', clf.score(scaled_X_train, y_train))\n",
    "print('Test accuracy:', clf.score(scaled_X_test, y_test))\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(clf, scaled_X_train, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "print('Cross-Validation Scores:', cv_scores)\n",
    "print('Mean KFold Cross-Validation Accuracy:', cv_scores.mean())\n",
    "\n",
    "# Classification Report\n",
    "y_predictions = clf.predict(scaled_X_test)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_predictions)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
